{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24747\\AllProjects\\Pycharm\\pythonProject\\text-classification\\src\\utils\\..\\..\\data\\news\\12-03-12-10\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from data_process.data_scraping import get_news_base_path\n",
    "\n",
    "\n",
    "def get_latest_news_dir():\n",
    "    date_format = \"%m-%d-%H-%M\"\n",
    "    dir_list = [datetime.strptime(ele, date_format) for ele in os.listdir(get_news_base_path())]\n",
    "    return max(dir_list).strftime(date_format)\n",
    "\n",
    "\n",
    "def get_latest_news_path():\n",
    "    return os.path.join(get_news_base_path(), get_latest_news_dir())\n",
    "\n",
    "\n",
    "print(get_latest_news_path())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content category\n",
      "0  前中国体操队长创造历史！打封闭夺世锦赛首金，弥补弱势项目空白_商春松_决赛_高低杠跑酷这项极...       体育\n",
      "1  青岛市滑板队参加2024年山东省滑板锦标赛获12金12银6铜_金牌_团体_乙组11月17日，...       体育\n",
      "2  历经45年，“六姐妹”实现满堂红，中国体操创造世锦赛大满贯伟业_项目_世界_奥运商春松问鼎2...       体育\n",
      "3  潍坊市潍城区芙蓉小学举行队列队形暨广播体操比赛_智则国_都为一规一矩有章法，一言一行好习惯。...       体育\n",
      "4  “长江潮”华东青少年赛艇公开赛在南京举办_泱波_比赛_七里河中新网江苏新闻11月18日电 (...       体育\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(get_latest_news_path(), '体育.txt'), sep='\\n', header=None)\n",
    "df.columns = ['content']\n",
    "df['category'] = '体育'\n",
    "print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "体育.txt\t1966\n",
      "健康.txt\t1599\n",
      "公益.txt\t1571\n",
      "军事.txt\t2262\n",
      "历史.txt\t1232\n",
      "房产.txt\t2109\n",
      "政务.txt\t1720\n",
      "教育.txt\t1045\n",
      "旅游.txt\t2575\n",
      "游戏.txt\t2225\n",
      "科技.txt\t1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\24747\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美食.txt\t1156\n",
      "财经.txt\t2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.534 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content category  label\n",
      "0  中国 体操 队长 创造 历史 封闭 世锦赛 首金 弥补 弱势 项目 空白 商春松 决赛 高低...       体育      0\n",
      "1  青岛市 滑板 参加 山东省 滑板 锦标赛 金银铜 金牌 团体 乙组 中国 体育彩票 山东省 ...       体育      0\n",
      "2  历经 姐妹 满堂红 中国 体操 创造 世锦赛 大满贯 伟业 项目 世界 奥运 商春松 问鼎 ...       体育      0\n",
      "3  潍坊市 潍城区 芙蓉 小学 队列 队形 广播体操 比赛 智则国 一规 一矩 章法 一言一行 ...       体育      0\n",
      "4  长江 华东 青少年 赛艇 公开赛 南京 举办 泱波 比赛 七里河 中新网 江苏 新闻 日电 ...       体育      0\n",
      "(23517, 3)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from src.utils.data_input import get_path\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "\n",
    "def read_news_data():\n",
    "    \"\"\"\n",
    "    将最近一次news数据读入\n",
    "    :return: Dataframe columns=['content', 'category']\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(columns=['content', 'category'])\n",
    "    for category_file_name in os.listdir(get_latest_news_path()):\n",
    "        category_path = os.path.join(get_latest_news_path(), category_file_name)\n",
    "        category_data = pd.read_csv(category_path, sep='\\n', header=None)\n",
    "        category_data.columns = ['content']\n",
    "        print(f'{category_file_name}\\t{category_data.shape[0]}')\n",
    "        category_data['category'] = category_file_name.rstrip('.txt')\n",
    "        data = pd.concat([data, category_data], ignore_index=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def cut_remove_stopwords(text, stop_words: set):\n",
    "    # 使用正则表达式去除非中文字符，只保留中文\n",
    "    new_text = \"\".join(re.findall('[\\u4e00-\\u9fa5]+', text, re.S))\n",
    "    # 使用jieba进行分词\n",
    "    words = jieba.lcut(new_text)\n",
    "    # 去除停用词\n",
    "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "def news_data_process(data: pd.DataFrame, stopwords_path=os.path.join(get_path(), 'stopwords.txt')):\n",
    "    \"\"\"\n",
    "    1.对分类进行编码\n",
    "    2.对新闻文本进行分词\n",
    "    3.对新闻文本去除停用词\n",
    "    :param stopwords_path: 停用词路径\n",
    "    :param data: 新闻文本数据\n",
    "    :return: 处理好的data\n",
    "    \"\"\"\n",
    "    # 对category进行编码\n",
    "    data['label'] = pd.factorize(data['category'])[0]\n",
    "    # 对content进行分词并去除停用词\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        stop_words = set([line.strip() for line in f.readlines()])\n",
    "    data['content'] = data['content'].apply(lambda x: cut_remove_stopwords(x, stop_words))\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_news_data(data: pd.DataFrame):\n",
    "    # 创建保存路径\n",
    "    folder_path = os.path.join(get_path(), get_latest_news_dir())\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    data.to_csv(os.path.join(folder_path, 'news.csv'), index=False)\n",
    "\n",
    "\n",
    "dt = read_news_data()\n",
    "dt = news_data_process(dt)\n",
    "print(dt.head())\n",
    "print(dt.shape)\n",
    "write_news_data(dt)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型准确率: 0.82\n",
      "精确率(Precision): 0.85\n",
      "召回率(Recall): 0.80\n",
      "F1值: 0.81\n"
     ]
    }
   ],
   "source": [
    "from src.utils.data_input import get_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = dt['content']  # 特征数据\n",
    "y = dt['label']  # 标签数据\n",
    "\n",
    "# 分割数据集，测试集占30%，随机状态设置为42以保证结果可复现\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train, y_train, X_test, y_test = get_dataset()\n",
    "# 创建一个管道，包括CountVectorizer、TfidfTransformer和MultinomialNB\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# 在训练数据上拟合模型\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 在测试数据上进行预测\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"模型准确率: {accuracy:.2f}\")\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 假设 y_test 是真实的标签，y_pred 是模型预测的标签\n",
    "# 计算精确率\n",
    "precision = precision_score(y_test, y_pred, average='macro')  # 'macro'表示对所有类别的平均值\n",
    "# 计算召回率\n",
    "recall = recall_score(y_test, y_pred, average='macro')  # 'macro'表示对所有类别的平均值\n",
    "# 计算F1值\n",
    "f1 = f1_score(y_test, y_pred, average='macro')  # 'macro'表示对所有类别的平均值\n",
    "\n",
    "print(f\"精确率(Precision): {precision:.2f}\")\n",
    "print(f\"召回率(Recall): {recall:.2f}\")\n",
    "print(f\"F1值: {f1:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表: {'kimi': 11, 'is': 10, 'chatbot': 6, 'developed': 9, 'by': 4, 'moonshot': 12, 'ai': 0, 'company': 7, 'that': 16, 'creates': 8, 'assistants': 3, 'can': 5, 'process': 13, 'text': 15, 'and': 1, 'assist': 2, 'with': 18, 'various': 17, 'tasks': 14}\n",
      "词频矩阵:\n",
      " [[1 0 0 0 1 0 1 0 0 1 1 1 1 0 0 0 0 0 0]\n",
      " [2 0 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0]\n",
      " [0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 1]]\n",
      "TF-IDF 矩阵:\n",
      " [[0.32992832 0.         0.         0.         0.43381609 0.\n",
      "  0.43381609 0.         0.         0.43381609 0.32992832 0.32992832\n",
      "  0.32992832 0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.55650888 0.         0.         0.36587115 0.         0.\n",
      "  0.         0.36587115 0.36587115 0.         0.27825444 0.\n",
      "  0.27825444 0.         0.         0.         0.36587115 0.\n",
      "  0.        ]\n",
      " [0.         0.34142622 0.34142622 0.         0.         0.34142622\n",
      "  0.         0.         0.         0.         0.         0.25966344\n",
      "  0.         0.34142622 0.34142622 0.34142622 0.         0.34142622\n",
      "  0.34142622]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# 准备文本数据\n",
    "documents = [\n",
    "    \"Kimi is a chatbot developed by Moonshot AI.\",\n",
    "    \"Moonshot AI is a company that creates AI assistants.\",\n",
    "    \"Kimi can process text and assist with various tasks.\"\n",
    "]\n",
    "\n",
    "# 使用 CountVectorizer 进行词频统计\n",
    "vectorizer = CountVectorizer()\n",
    "X_counts = vectorizer.fit_transform(documents)\n",
    "print(\"词汇表:\", vectorizer.vocabulary_)\n",
    "print(\"词频矩阵:\\n\", X_counts.toarray())\n",
    "\n",
    "# 使用 TfidfTransformer 转换为 TF-IDF 特征\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_counts)\n",
    "print(\"TF-IDF 矩阵:\\n\", X_tfidf.toarray())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}